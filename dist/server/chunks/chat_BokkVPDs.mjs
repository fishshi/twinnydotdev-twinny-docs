import { e as createComponent, r as renderTemplate, m as maybeRenderHead, u as unescapeHTML } from './astro_D8JpLML5.mjs';
import 'kleur/colors';
import 'clsx';
import 'cssesc';

const html = "<p>Chat with twinny and leverage workspace embeddings for enhanced context.</p>\n<h3 id=\"open-side-panel\">Open Side Panel</h3>\n<p>To use twinny Chat, access it from the VSCode sidebar. twinny will retain the chat history between sessions. You can find the chat history by clicking on the History icon on the top panel.</p>\n<h3 id=\"context-and-code-selection\">Context and Code Selection</h3>\n<p>When you highlight/select code in your editor, twinny will use that as the context for the chat message. If you have not selected any code, it will use the message alone and any previous messages. You can also right-click on selected code and select a twinny option to refactor, explain and perform other actions.</p>\n<h3 id=\"workspace-embeddings\">Workspace Embeddings</h3>\n<p>twinny now supports workspace embeddings to provide more relevant context for your queries.</p>\n<h3 id=\"rag-and-mentions-how-it-works\">RAG and Mentions How it Works</h3>\n<ol>\n<li>Your workspace documents are embedded and stored when you click the “Embed workspace documents” button.</li>\n<li>When you send a message, twinny looks up relevant chunks from the embeddings.</li>\n<li>These chunks are reranked and used as additional context for your query.</li>\n<li>Use the <code dir=\"auto\">@workspace</code> mention in the chat to search for relevant documents.</li>\n<li>Use <code dir=\"auto\">@problems</code> for code issues</li>\n<li>Use <code dir=\"auto\">@</code> to add context for specific files in the workspace.</li>\n</ol>\n<h3 id=\"embedding-settings\">Embedding Settings</h3>\n<ul>\n<li><strong>Embedding Provider</strong>: By default, twinny uses Ollama Embedding (all-minilm:latest\n) for embeddings.</li>\n<li><strong>Provider Details</strong>:\n<ul>\n<li>Label: Ollama Embedding</li>\n<li>Provider: ollama</li>\n<li>Type: embedding</li>\n<li>Hostname: 0.0.0.0</li>\n<li>Path: /v1/embeddings</li>\n<li>Protocol: http</li>\n<li>Port: 11434</li>\n</ul>\n</li>\n</ul>\n<p>You can update these settings to use a different embedding provider if needed. In theory, most providers should work as long as they return the correct data structure.</p>\n<p>For HTTPS providers like OpenAI, a local proxy such as LiteLLM is required for it to work.</p>\n<h3 id=\"rerank-probability-threshold\">Rerank Probability Threshold</h3>\n<p>You can adjust the rerank probability threshold (default: 0.14) to control which results are included as context. A lower threshold means more results are likely to be included.</p>\n<h3 id=\"toggling-context\">Toggling Context</h3>\n<p>The database-like icon with lines allows you to turn on/off the use of embedded context for each message.</p>\n<h3 id=\"embedding-workspace-documents\">Embedding Workspace Documents</h3>\n<p>To include your workspace documents in the embeddings, use the “Embed workspace documents” button in the settings panel.</p>";

				const frontmatter = {"title":"Chat","description":"Chat with twinny"};
				const file = "/home/richard/Desktop/twinny/twinny-docs/src/content/docs/general/chat.md";
				const url = undefined;
				function rawContent() {
					return "\nChat with twinny and leverage workspace embeddings for enhanced context.\n\n### Open Side Panel\n\nTo use twinny Chat, access it from the VSCode sidebar. twinny will retain the chat history between sessions. You can find the chat history by clicking on the History icon on the top panel.\n\n### Context and Code Selection\n\nWhen you highlight/select code in your editor, twinny will use that as the context for the chat message. If you have not selected any code, it will use the message alone and any previous messages. You can also right-click on selected code and select a twinny option to refactor, explain and perform other actions.\n\n### Workspace Embeddings\n\ntwinny now supports workspace embeddings to provide more relevant context for your queries.\n\n### RAG and Mentions How it Works\n\n1. Your workspace documents are embedded and stored when you click the \"Embed workspace documents\" button.\n2. When you send a message, twinny looks up relevant chunks from the embeddings.\n3. These chunks are reranked and used as additional context for your query.\n4. Use the `@workspace` mention in the chat to search for relevant documents.\n5. Use `@problems` for code issues\n6. Use `@` to add context for specific files in the workspace. \n\n### Embedding Settings\n\n- **Embedding Provider**: By default, twinny uses Ollama Embedding (all-minilm:latest) for embeddings.\n- **Provider Details**:\n  - Label: Ollama Embedding\n  - Provider: ollama\n  - Type: embedding\n  - Hostname: 0.0.0.0\n  - Path: /v1/embeddings\n  - Protocol: http\n  - Port: 11434\n\nYou can update these settings to use a different embedding provider if needed. In theory, most providers should work as long as they return the correct data structure.\n\nFor HTTPS providers like OpenAI, a local proxy such as LiteLLM is required for it to work.\n\n### Rerank Probability Threshold\n\nYou can adjust the rerank probability threshold (default: 0.14) to control which results are included as context. A lower threshold means more results are likely to be included.\n\n### Toggling Context\n\nThe database-like icon with lines allows you to turn on/off the use of embedded context for each message.\n\n### Embedding Workspace Documents\n\nTo include your workspace documents in the embeddings, use the \"Embed workspace documents\" button in the settings panel.\n";
				}
				function compiledContent() {
					return html;
				}
				function getHeadings() {
					return [{"depth":3,"slug":"open-side-panel","text":"Open Side Panel"},{"depth":3,"slug":"context-and-code-selection","text":"Context and Code Selection"},{"depth":3,"slug":"workspace-embeddings","text":"Workspace Embeddings"},{"depth":3,"slug":"rag-and-mentions-how-it-works","text":"RAG and Mentions How it Works"},{"depth":3,"slug":"embedding-settings","text":"Embedding Settings"},{"depth":3,"slug":"rerank-probability-threshold","text":"Rerank Probability Threshold"},{"depth":3,"slug":"toggling-context","text":"Toggling Context"},{"depth":3,"slug":"embedding-workspace-documents","text":"Embedding Workspace Documents"}];
				}

				const Content = createComponent((result, _props, slots) => {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;

					return renderTemplate`${maybeRenderHead()}${unescapeHTML(html)}`;
				});

export { Content, compiledContent, Content as default, file, frontmatter, getHeadings, rawContent, url };
